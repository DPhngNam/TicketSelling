# logstash.conf

input {
  http {
    port => 5001
    codec => json # Let the input codec attempt to parse the incoming JSON.
                  # If the body is a JSON array like [{}, {}], this codec
                  # should parse it. The key is where it places this parsed array.
                  # Often, it might place the raw array string into the 'message' field
                  # if it can't map the array directly to a Logstash event structure,
                  # and it will add a _jsonparsefailure tag.
  }
}

filter {
  # This condition checks if the initial JSON parsing by the input codec failed
  # AND the 'message' field (which would contain the raw body on input codec failure)
  # actually looks like a string representation of a JSON array.
  if "_jsonparsefailure" in [tags] and [message] =~ /^\[.*\]$/ {
    # If the above is true, 'message' contains the stringified JSON array.
    # Parse this string array into an actual Logstash array field.
    json {
      source => "message"
      target => "event_payload_array" # Store the parsed array here
    }

    # If 'event_payload_array' was successfully created (meaning 'message' was a valid JSON array string)
    if [event_payload_array] {
      # Split the array: create a new Logstash event for each element in 'event_payload_array'.
      # The fields from each JSON object in the array will become the root fields of the new events.
      split {
        field => "event_payload_array"
      }
      # The original event (that had the _jsonparsefailure tag and the full array in 'message')
      # is effectively discarded and replaced by these new individual events.
      # We might want to remove the 'message' and 'event_payload_array' fields from the *original* event
      # if it somehow wasn't fully replaced, but 'split' usually handles this.
      # For the newly created split events, they shouldn't have these fields unless copied weirdly.
    }
    # If for some reason 'event_payload_array' was not created even if message looked like an array,
    # the original event with _jsonparsefailure will pass through.
  }
  # else:
  # If there was no "_jsonparsefailure" from the input codec, it implies the input
  # might have been a single JSON object (not an array from a batch) and was parsed correctly.
  # Or, the input codec handled the array in a way that didn't require this specific recovery.
  # For now, we only explicitly handle the failure-and-recovery path for arrays.

  # Date parsing: This applies to each event (either a single one, or each one from the split).
  # ElasticsearchJsonFormatter from Serilog usually provides '@timestamp' in a compatible ISO8601 format.
    if [@timestamp] and "[@timestamp]" =~ /.+/ {
      date {
        match => [ "@timestamp",
                   "ISO8601"
                 ]
        target => "@timestamp"
      }
    }

  # Clean up any leftover original 'message' field from the split events,
  # if the JSON content was successfully parsed and promoted to the root.
  # This should run *after* the split and potential date parsing.
  if !("_jsonparsefailure" in [tags]) { # Assuming the json filter inside the conditional didn't add its own failure tag to split events
      mutate {
          remove_field => ["message"] # Remove only if it was successfully parsed and split
      }
  }
  # Also, potentially remove http headers if they are noisy on every event
  # mutate {
  #   remove_field => ["headers", "http"] # Consider if you need this info per event
  # }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "venueservice-logs-%{+YYYY.MM.dd}"
    # user => "elastic" # If Elasticsearch security is enabled
    # password => "your_password" # If Elasticsearch security is enabled
  }

  # For debugging - shows what's being sent to Elasticsearch
  stdout {
    codec => rubydebug
  }
}