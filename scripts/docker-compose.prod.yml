services:
  userservice:
    image: tqt0304/userservice:latest
    environment:
      ASPNETCORE_ENVIRONMENT: Production
    secrets:
      # Grant the service access to the Swarm secret
      - source: db_connection_string # Name of the secret IN SWARM
        target: ConnectionStrings__UserServiceDb # Filename inside /run/secrets/. Matches AddKeyPerFile structure.
    networks:
      - backend-net
    deploy:
      replicas: 2
      placement:
        constraints: [node.role == worker] # Place on worker nodes
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure

  # Message Queue
  rabbitmq:
    image: rabbitmq:3.13.7-management-alpine
    hostname: rabbitmq # Consistent hostname
    ports:
      - "15672:15672" # Management UI port
    volumes:
      - ~/data_volume/rabbitmq_data:/var/lib/rabbitmq/ # Persist data
    configs:
      - source: rabbitmq_config
        target: /etc/rabbitmq/rabbitmq.conf
    networks:
      - backend-net
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == manager]
      restart_policy:
        condition: on-failure
  # Logging - Elasticsearch (Data Store)
  elasticsearch:
    image: elasticsearch:7.17.10
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m" # Adjust heap size
    ulimits: # Required by Elasticsearch
      memlock:
        soft: -1
        hard: -1
    volumes:
      - ./elasticsearch_data:/usr/share/elasticsearch/data # Persist data using named volume
    networks:
      - backend-net
    ports:
      - "9200:9200" # API port
    # this healthcheck ensures ES is ready before dependent services fully start actions
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -sf http://localhost:9200/_cluster/health || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == worker] # Place on worker nodes
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
  logstash:
    image: logstash:7.17.10
    ports:
      - "5044:5044" # Port for Beats input
      - "5000:5000/tcp" # Port for TCP input
      - "5000:5000/udp" # Port for UDP input
    environment:
      LS_JAVA_OPTS: "-Xms256m -Xmx256m" # Adjust heap size
    volumes:
      - ./logstash_data:/usr/share/logstash/data
    configs:
      - source: logstash_pipeline_config
        target: /usr/share/logstash/pipeline/logstash.conf
    networks:
      - backend-net
    depends_on:
      elasticsearch:
        condition: service_healthy
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == worker] # Place on worker nodes
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
  # Logging - Kibana (UI)
  kibana:
    image: kibana:7.17.10 # Match ELK stack versions
    ports:
      - "5601:5601" # Kibana UI port
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200 # Points to the ES service name
      SERVER_NAME: kibana.example.com # Set server name
      ELASTICSEARCH_SERVICEACCOUNTTOKEN: false # Disable service account token
    networks:
      - backend-net
    depends_on:
      elasticsearch:
        condition: service_healthy
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == worker] # Place on worker nodes
      restart_policy:
        condition: on-failure
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
#
#  # Monitoring - Prometheus (Data Store & Scraper)
#  prometheus:
#    image: prom/prometheus:v2.45.0 # Use a specific version
#    ports:
#      - "9090:9090" # Prometheus UI/API port
#    volumes:
#      - /data/prometheus:/prometheus # Persist data
#      # Mount the configuration file
#      - /path/on/host/prometheus.yml:/etc/prometheus/prometheus.yml # Option 1: Bind mount config
#    # Option 2: Use Docker Configs (Recommended for Swarm)
#    # configs:
#    #   - source: prometheus_config
#    #     target: /etc/prometheus/prometheus.yml
#    # command: # Command needed when using Docker Configs
#    #   - '--config.file=/etc/prometheus/prometheus.yml'
#    #   - '--storage.tsdb.path=/prometheus'
#    #   - '--web.console.libraries=/usr/share/prometheus/console_libraries'
#    #   - '--web.console.templates=/usr/share/prometheus/consoles'
#    networks:
#      - backend-net
#    deploy:
#      replicas: 1
#      placement:
#        constraints: [node.role == manager] # Often good to run on a manager
#      restart_policy:
#        condition: on-failure
#
#  # Monitoring - Grafana (UI)
#  grafana:
#    image: grafana/grafana:9.5.3 # Use a specific version
#    ports:
#      - "3000:3000" # Grafana UI port
#    volumes:
#      - /data/grafana_data:/var/lib/grafana

networks:
  backend-net:
    driver: overlay

configs:
  rabbitmq_config:
    external: true
  logstash_pipeline_config:
    file: ./logstash/pipeline/logstash.conf

secrets:
  db_connection_string:
    external: true
